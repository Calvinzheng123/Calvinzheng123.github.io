<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Project 2: Fraud Detection — Bank Account Fraud (BAF Base)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script src="https://cdn.tailwindcss.com"></script>
  <meta name="description" content="Fraud detection classification with Logistic Regression and Random Forest on the Feedzai BAF Base dataset. Includes EDA visuals, evaluation, threshold tuning, impact."/>
</head>
<body class="bg-white text-gray-900">
  <header class="max-w-3xl mx-auto p-6">
    <a href="index.html" class="text-sm text-blue-600 underline">← Back</a>
    <h1 class="text-3xl font-bold mt-2">Project 2: Fraud Detection — Bank Account Fraud (BAF Base)</h1>
    <p class="mt-2 text-gray-700">
      Dataset:
      <a class="underline text-blue-600" href="https://github.com/feedzai/bank-account-fraud" target="_blank" rel="noopener">Feedzai — Bank Account Fraud (BAF)</a>
      (<a class="underline text-blue-600" href="https://www.kaggle.com/datasets/whenamancodes/bank-account-fraud-baf-dataset" target="_blank" rel="noopener">Kaggle mirror</a>).
    </p>
    <p class="mt-1 text-gray-700">Task: binary classification — predict <code>fraud_bool</code> (1 = fraud, 0 = non-fraud).</p>
  </header>

  <main class="max-w-3xl mx-auto p-6 space-y-10">
    <!-- ===== Storytelling / Portfolio Post ===== -->
    <section>
      <h2 class="text-2xl font-semibold">Story: Catch fraud without blowing up false alarms</h2>
      <p class="mt-2">Fraud is rare (~1%). I built two classifiers — Logistic Regression (baseline) and Random Forest (nonlinear) — then tuned cutoffs to favor recall. The goal: catch as many frauds as possible while keeping false positives manageable.</p>

      <!-- Problem -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Problem</h3>
        <p class="mt-1">Can we classify transactions as fraud vs. non-fraud, and what’s the precision/recall trade-off that makes sense? Sub-questions: which features matter, and how do different models behave under heavy class imbalance?</p>
      </div>

      <!-- Data -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Data</h3>
        <p class="mt-1">
          ~1.1M rows; target <code>fraud_bool</code>. Mix of demographics (age/income buckets, employment), geography (zips), transaction attributes, and a <code>month</code> field. Some fields are anonymized or bucketed. Fraud rate is low (~1–2%), which drives metric choices.
        </p>
      </div>

      <!-- Visuals -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Visualizations</h3>
        <div class="space-y-6 mt-2">
          <figure>
            <img src="figs/baf_class_balance.png" alt="Fraud vs non-fraud class counts bar chart" class="w-full rounded border" />
            <figcaption class="text-sm text-gray-600 mt-1">Severe imbalance: fraud is ~1–2% of all rows.</figcaption>
          </figure>
          <figure>
            <img src="figs/baf_corr_heatmap.png" alt="Correlation heatmap of numeric features and target" class="w-full rounded border" />
            <figcaption class="text-sm text-gray-600 mt-1">Numeric correlations are modest; non-linear models are better suited.</figcaption>
          </figure>
          <figure>
            <img src="figs/baf_roc_compare.png" alt="ROC curves for Logistic Regression and Random Forest" class="w-full rounded border" />
            <figcaption class="text-sm text-gray-600 mt-1">ROC: Random Forest separates classes better than Logistic Regression.</figcaption>
          </figure>
          <figure>
            <img src="figs/baf_pr_compare.png" alt="Precision-Recall curves for Logistic Regression and Random Forest" class="w-full rounded border" />
            <figcaption class="text-sm text-gray-600 mt-1">PR curves matter under imbalance; RF’s PR-AUC is far stronger.</figcaption>
          </figure>
          <figure>
            <img src="figs/baf_rf_importance.png" alt="Top feature importances from Random Forest" class="w-full rounded border" />
            <figcaption class="text-sm text-gray-600 mt-1">Top features (e.g., device OS, address history, credit risk) make sense as fraud indicators.</figcaption>
          </figure>
        </div>
      </div>

      <!-- Results & Storytelling -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Results & Storytelling</h3>
        <p class="mt-2">
          Logistic Regression struggled (PR-AUC ≈ 0.046) while Random Forest performed much better (PR-AUC ≈ 0.13, ROC-AUC ≈ 0.876). Lowering the threshold from 0.5 to ~0.31 raised recall above 85%, catching most frauds but dropping precision to 3–4%. The confusion matrix at that cutoff shows ~1,890 frauds caught, ~316 missed, but over 54k false positives. This trade-off is acceptable in fraud detection where missing fraud is costlier than flagging too much.
        </p>
        <p class="mt-2">
          Feature importances gave interpretability: unstable addresses, Windows devices, and weak credit risk scores were all strong signals. These align with known fraud risk factors and provide analysts with tangible review cues.
        </p>
      </div>

      <!-- Learnings -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Key Takeaways</h3>
        <ul class="list-disc pl-6 mt-2 space-y-1">
          <li>Accuracy is misleading on imbalanced data; PR-AUC and recall drive meaningful evaluation.</li>
          <li>Logistic Regression is a weak baseline, while Random Forest separates classes much better.</li>
          <li>Threshold choice directly controls recall vs precision; the default 0.5 cutoff is rarely optimal.</li>
          <li>Model insights (feature importances) connect predictions to real-world fraud behaviors.</li>
        </ul>
      </div>

      <!-- Impact & Limits -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Impact & Limits</h3>
        <p class="mt-1">
          Positive: higher fraud capture reduces direct financial loss. Negative: false positives create customer friction (blocked accounts, declined transactions). Ethical: some features (zip, income) may proxy for demographics, so fairness monitoring is necessary. Limits: dataset is anonymized and snapshot-based, so results are not causal and may not generalize to live fraud streams.
        </p>
      </div>
    </section>

    <!-- ===== Technical Report ===== -->
    <section class="border-t pt-8">
      <h2 class="text-2xl font-semibold">Technical Report (Process & Reflection)</h2>

      <nav class="mt-4 text-sm text-blue-700">
        <ul class="list-disc pl-6 space-y-1">
          <li><a href="#dataset-origin" class="underline">Dataset origin & description</a></li>
          <li><a href="#preprocessing" class="underline">Preprocessing</a></li>
          <li><a href="#viz" class="underline">Data understanding & visuals</a></li>
          <li><a href="#modeling" class="underline">Modeling</a></li>
          <li><a href="#evaluation" class="underline">Evaluation & thresholds</a></li>
          <li><a href="#impact" class="underline">Impact</a></li>
          <li><a href="#code" class="underline">Code & notebook</a></li>
          <li><a href="#refs" class="underline">References</a></li>
        </ul>
      </nav>

      <!-- Dataset origin -->
      <section id="dataset-origin" class="mt-6">
        <h3 class="text-xl font-semibold">Dataset origin & description</h3>
        <p class="mt-2">
          Source: <a class="underline text-blue-600" href="https://github.com/feedzai/bank-account-fraud" target="_blank" rel="noopener">Feedzai BAF</a> (with a <a class="underline text-blue-600" href="https://www.kaggle.com/datasets/whenamancodes/bank-account-fraud-baf-dataset" target="_blank" rel="noopener">Kaggle mirror</a>). I use the <strong>Base</strong> variant. Target is <code>fraud_bool</code>. Features include demographics, geography, transactional summaries, and month. Fraud rate ≈ 1–2%.
        </p>
      </section>

      <!-- Preprocessing -->
      <section id="preprocessing" class="mt-6">
        <h3 class="text-xl font-semibold">Preprocessing (with rationale)</h3>
        <ul class="list-disc pl-6 mt-2 space-y-2">
          <li>Target: cast <code>fraud_bool</code> to int (0/1).</li>
          <li>Categoricals → dummies with <code>pd.get_dummies(drop_first=True)</code>.</li>
          <li>Train/Test split: stratified 80/20 to preserve fraud ratio.</li>
          <li>Class imbalance: <code>class_weight="balanced"</code> in both models; tuned thresholds at eval time.</li>
          <li>Optional: bucket rare categories to reduce feature explosion and runtime.</li>
        </ul>
      </section>

      <!-- Viz -->
      <section id="viz" class="mt-6">
        <h3 class="text-xl font-semibold">Data understanding & visuals</h3>
        <p class="mt-2">Class imbalance confirmed the need for PR-AUC and recall. Amount distributions and correlations suggested non-linear models could uncover useful interactions.</p>
      </section>

      <!-- Modeling -->
      <section id="modeling" class="mt-6">
        <h3 class="text-xl font-semibold">Modeling</h3>
        <ul class="list-disc pl-6 mt-2 space-y-2">
          <li><strong>Logistic Regression</strong> — interpretable, linear baseline; struggled with convergence and precision.</li>
          <li><strong>Random Forest</strong> — nonlinear ensemble; handled interactions better and delivered stronger AUCs.</li>
        </ul>
      </section>

      <!-- Evaluation -->
      <section id="evaluation" class="mt-6">
        <h3 class="text-xl font-semibold">Evaluation & thresholds</h3>
        <ul class="list-disc pl-6 mt-2 space-y-2">
          <li><strong>Metrics:</strong> ROC-AUC, PR-AUC, Precision/Recall/F1.</li>
          <li>Example results:
            <ul class="list-disc pl-6 mt-1">
              <li>LogReg — ROC-AUC ≈ 0.73, PR-AUC ≈ 0.046, Recall ≈ 0.65, Precision ≈ 0.02.</li>
              <li>Random Forest — ROC-AUC ≈ 0.876, PR-AUC ≈ 0.13, Recall ≈ 0.63, Precision ≈ 0.07.</li>
            </ul>
          </li>
          <li><strong>Threshold tuning:</strong> lowering cutoff boosted recall >80% but at the cost of precision (~3–4%).</li>
        </ul>
      </section>

      <!-- Impact -->
      <section id="impact" class="mt-6">
        <h3 class="text-xl font-semibold">Impact</h3>
        <p class="mt-2">
          Catching fraud reduces losses, but false positives create customer frustration. Ethical concerns include bias from demographic proxies. Limits: dataset is static and anonymized, not live transactions.
        </p>
      </section>

      <!-- Code & Notebook links -->
      <section id="code" class="mt-6">
        <h3 class="text-xl font-semibold">Code & Notebook</h3>
        <p class="mt-1">Reproducible assets:</p>
        <div class="space-y-2">
          <p><a class="underline text-blue-600" href="notebooks/project2_baf_fraud.ipynb" download>Download the Jupyter Notebook</a></p>
          <div class="space-x-3 mt-2">
            <a class="inline-block px-3 py-2 rounded bg-black text-white" href="https://colab.research.google.com/github/Calvinzheng123/Calvinzheng123.github.io/blob/main/notebooks/project2_baf_fraud.ipynb" target="_blank" rel="noopener">Open in Colab</a>
            <a class="inline-block px-3 py-2 rounded bg-gray-200" href="https://nbviewer.org/github/Calvinzheng123/Calvinzheng123.github.io/blob/main/notebooks/project2_baf_fraud.ipynb" target="_blank" rel="noopener">View on nbviewer</a>
          </div>
        </div>
      </section>

      <!-- References -->
      <section id="refs" class="mt-8">
        <h3 class="text-xl font-semibold">References</h3>
        <ul class="list-disc pl-6 mt-2">
          <li>Dataset: <a class="underline text-blue-600" href="https://github.com/feedzai/bank-account-fraud" target="_blank" rel="noopener">Feedzai BAF (Base)</a> / <a class="underline text-blue-600" href="https://www.kaggle.com/datasets/whenamancodes/bank-account-fraud-baf-dataset" target="_blank" rel="noopener">Kaggle mirror</a></li>
          <li>Libraries: pandas, scikit-learn, matplotlib, seaborn</li>
          <li>Transparency: ChatGPT assisted with scaffolding and write-up organization.</li>
        </ul>
      </section>
    </section>
  </main>

  <footer class="max-w-3xl mx-auto p-6 text-sm text-gray-500">
    © <span id="y"></span> Calvin Zheng
  </footer>
  <script>document.getElementById('y').textContent = new Date().getFullYear();</script>
</body>
</html>
