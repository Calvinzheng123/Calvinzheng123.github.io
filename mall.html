<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Project 4: Mall Customer Segmentation with Clustering</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script src="https://cdn.tailwindcss.com"></script>
  <meta
    name="description"
    content="Unsupervised clustering on a mall customer dataset using K-Means and Agglomerative clustering to discover behavior-based segments for marketing."
  />
</head>

<body class="bg-white text-gray-900">
  <header class="max-w-3xl mx-auto p-6">
    <a href="index.html" class="text-sm text-blue-600 underline">← Back</a>
    <h1 class="text-3xl font-bold mt-2">Project 4: Mall Customer Segmentation with Clustering</h1>
    <p class="mt-2 text-gray-700">
      Dataset:
      <a class="underline text-blue-600"
         href="https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python"
         target="_blank" rel="noopener">
        Mall Customer Segmentation Data (Kaggle)
      </a>
    </p>
    <p class="mt-1 text-gray-700">
      Goal: use clustering (K-Means + Agglomerative) to group mall customers by income and spending behavior, then interpret
      the segments for marketing strategy and ethical impact.
    </p>
  </header>

  <main class="max-w-3xl mx-auto p-6 space-y-10">
    <!-- ===== Story Section ===== -->
    <section>
      <h2 class="text-2xl font-semibold">Story: Finding Natural Customer Segments</h2>
      <p class="mt-2">
        The mall wants more targeted marketing instead of blasting the same deals to everyone. All they have is simple
        customer data: gender, age, annual income, and a spending score from 1–100.
        Rather than pre-define labels like “VIP” or “budget,” I used unsupervised clustering to let the data form its own groups
        and then translated those clusters into business language.
      </p>

      <!-- Problem -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Problem</h3>
        <p class="mt-1">
          The core question: <strong>do distinct segments of customers exist based on income and spending score, and what do they
          look like?</strong> In particular:
        </p>
        <ul class="list-disc pl-6 mt-2 space-y-1">
          <li>Can we find high-income, low-spending customers who might be disengaged?</li>
          <li>Can we find lower-income but loyal, high-spending shoppers?</li>
          <li>How do these groups differ enough to justify different marketing strategies?</li>
        </ul>
      </div>

      <!-- Data -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Data</h3>
        <p class="mt-1">
          The dataset contains <strong>200 customers</strong> with 5 columns:
        </p>
        <ul class="list-disc pl-6 mt-2 space-y-1">
          <li><code>CustomerID</code> &mdash; unique identifier (dropped for modeling).</li>
          <li><code>Gender</code> &mdash; Male / Female.</li>
          <li><code>Age</code> &mdash; customer age in years.</li>
          <li><code>Annual Income (k$)</code> &mdash; estimated yearly income in thousands.</li>
          <li><code>Spending Score (1-100)</code> &mdash; mall-assigned score based on spending and loyalty.</li>
        </ul>
        <p class="mt-2">
          It’s a small but clean dataset, which makes it good for visually understanding clustering behavior.
        </p>
      </div>

      <!-- Visuals -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Exploring the Data</h3>

        <figure class="mt-2">
          <img src="figs/mall_histograms.png" alt="Histograms of Age, Income, and Spending Score" class="w-full rounded border" />
          <figcaption class="text-sm text-gray-600 mt-1">
            Histograms show multi-peaked age distribution, a wide spread of income, and two broad groups of low vs high spenders.
          </figcaption>
        </figure>

        <figure class="mt-6">
          <img src="figs/mall_boxplots.png" alt="Boxplots of numeric features" class="w-full rounded border" />
          <figcaption class="text-sm text-gray-600 mt-1">
            Boxplots confirm moderate spread and a few high-income outliers near 130k.
          </figcaption>
        </figure>

        <figure class="mt-6">
          <img src="figs/mall_income_spend_gender.png" alt="Income vs Spending Score colored by gender" class="w-full rounded border" />
          <figcaption class="text-sm text-gray-600 mt-1">
            Income vs Spending Score by gender. The two genders mix across the space&mdash;behavior is driven more by money and spending than by gender.
          </figcaption>
        </figure>

        <p class="mt-4">
          Visually, the income–spending plot already hints at several blobs: a dense mid-income, mid-spend group, high-income
          low-spend customers, and clear high-spend pockets at different income levels. That’s exactly what clustering should formalize.
        </p>
      </div>

      <!-- Results -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Clustering Results (K-Means, k = 5)</h3>

        <figure class="mt-2">
          <img src="figs/mall_kmeans_k5.png" alt="K-Means clusters on income vs spending" class="w-full rounded border" />
          <figcaption class="text-sm text-gray-600 mt-1">
            K-Means with five clusters on scaled Annual Income and Spending Score. Each color is a discovered segment.
          </figcaption>
        </figure>

        <p class="mt-4">
          I ran K-Means for k = 2–10, checked inertia and silhouette scores, and visually inspected the clusters.
          k ≈ 4–5 looked reasonable; I chose <strong>k = 5</strong> because it separated a “middle” group while keeping interpretable segments.
        </p>

        <h4 class="mt-4 font-semibold">Cluster centers (back on original scale)</h4>
        <table class="w-full text-sm mt-3 border">
          <thead class="bg-gray-100 border-b">
            <tr>
              <th class="text-left p-2">Cluster</th>
              <th class="text-left p-2">Annual Income (k$)</th>
              <th class="text-left p-2">Spending Score</th>
              <th class="text-left p-2">Interpretation</th>
            </tr>
          </thead>
          <tbody>
            <tr class="border-b">
              <td class="p-2">0</td>
              <td class="p-2">≈ 55</td>
              <td class="p-2">≈ 50</td>
              <td class="p-2">Average income, average spending &mdash; core “middle” customers.</td>
            </tr>
            <tr class="border-b">
              <td class="p-2">1</td>
              <td class="p-2">≈ 87</td>
              <td class="p-2">≈ 82</td>
              <td class="p-2">High income, high spending &mdash; premium loyalists.</td>
            </tr>
            <tr class="border-b">
              <td class="p-2">2</td>
              <td class="p-2">≈ 26</td>
              <td class="p-2">≈ 79</td>
              <td class="p-2">Lower income, high spending &mdash; value-driven loyal shoppers.</td>
            </tr>
            <tr class="border-b">
              <td class="p-2">3</td>
              <td class="p-2">≈ 88</td>
              <td class="p-2">≈ 17</td>
              <td class="p-2">High income, low spending &mdash; affluent but disengaged.</td>
            </tr>
            <tr>
              <td class="p-2">4</td>
              <td class="p-2">≈ 26</td>
              <td class="p-2">≈ 21</td>
              <td class="p-2">Low income, low spending &mdash; occasional visitors.</td>
            </tr>
          </tbody>
        </table>

        <p class="mt-3">
          These segments line up with what a marketing team actually cares about: who is worth retaining, who is worth
          re-engaging, and who mostly passes through.
        </p>
      </div>

      <!-- Learnings -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Key Takeaways</h3>
        <ul class="list-disc pl-6 mt-2 space-y-1">
          <li>Clustering cleanly separated loyal high-spenders from under-utilized high-income customers.</li>
          <li>A low-income but high-spending segment shows that “budget” customers can still be very valuable.</li>
          <li>Gender wasn’t a major driver; the important factors were income and spending score.</li>
          <li>Cluster labels come from <eminterpretation</em>, not the algorithm. You still have to translate centroids into real business language.</li>
        </ul>
      </div>

      <!-- Impact -->
      <div class="mt-6">
        <h3 class="text-xl font-semibold">Impact & Reflection</h3>
        <p class="mt-2">
          This project shows how simple numeric features can support reasonable segmentation and better targeting of
          loyalty programs, promotions, and retention efforts. But it also highlights risks: over-focusing on high-income
          groups or high spenders can sideline low-income customers, and segments can easily slide into profiling if tied
          to sensitive attributes. Responsible use means regularly checking how segments are used and making sure baseline
          access and treatment stay fair across customers.
        </p>
      </div>
    </section>

    <!-- ===== Technical Report ===== -->
    <section class="border-t pt-8">
      <h2 class="text-2xl font-semibold">Technical Report (Process & Reflection)</h2>

      <nav class="mt-4 text-sm text-blue-700">
        <ul class="list-disc pl-6 space-y-1">
          <li><a href="#dataset" class="underline">Dataset origin & description</a></li>
          <li><a href="#preproc" class="underline">Preprocessing</a></li>
          <li><a href="#exp" class="underline">Clustering experiments</a></li>
          <li><a href="#impact" class="underline">Impact & limitations</a></li>
          <li><a href="#code" class="underline">Code & notebook</a></li>
        </ul>
      </nav>

      <!-- Dataset -->
      <section id="dataset" class="mt-6">
        <h3 class="text-xl font-semibold">Dataset origin & description</h3>
        <p class="mt-2">
          Source:
          <a class="underline text-blue-600"
             href="https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python"
             target="_blank" rel="noopener">
            Mall Customer Segmentation Data (Kaggle)
          </a>.
          The data contains 200 mall customers with demographic and behavioral attributes. There is no label or target
          column; the point of the project is <strong>unsupervised clustering</strong>.
        </p>
      </section>

      <!-- Preproc -->
      <section id="preproc" class="mt-6">
        <h3 class="text-xl font-semibold">Preprocessing</h3>
        <ul class="list-disc pl-6 mt-2 space-y-2">
          <li><strong>Dropped</strong> <code>CustomerID</code> since it's just an identifier with no numeric meaning.</li>
          <li><strong>Encoded</strong> <code>Gender</code> as a binary variable (0/1) to keep the feature numeric.</li>
          <li>
            Built two feature views:
            <ul class="list-disc pl-6 mt-1">
              <li><code>[Annual Income, Spending Score]</code> for 2D visualization and cluster storytelling.</li>
              <li><code>[Gender, Age, Annual Income, Spending Score]</code> for a fuller behavioral view.</li>
            </ul>
          </li>
          <li>
            <strong>Scaled</strong> all numeric features with <code>StandardScaler</code> so K-Means and Agglomerative
            clustering use distances that aren’t dominated by income’s larger numeric range.
          </li>
          <li>Checked for missing values; this dataset is already clean, so no imputation was needed.</li>
        </ul>
      </section>

      <!-- Experiments -->
      <section id="exp" class="mt-6">
        <h3 class="text-xl font-semibold">Clustering Experiments</h3>
        <ul class="list-disc pl-6 mt-2 space-y-4">
          <li>
            <strong>Exp 1 — K-Means on Income + Spending Score (2D):</strong>
            <p class="mt-1">
              I ran K-Means for k = 2–10 on standardized <code>[Annual Income, Spending Score]</code>.
              I used inertia (elbow) and silhouette scores to pick a reasonable range and then inspected the actual plots.
              k = 5 gave clean, interpretable blobs that matched visible structure in the scatterplot. This is the main model
              used for storytelling.
            </p>
          </li>

          <li>
            <strong>Exp 2 — K-Means on Full Feature Set:</strong>
            <p class="mt-1">
              Next, I extended K-Means to <code>[Gender, Age, Annual Income, Spending Score]</code>.
              This didn’t completely reshape the segments, but it did nudge cluster centers and slightly separate some age bands
              (e.g., younger high-spenders vs older moderate-spenders). The main story still revolved around income and score.
            </p>
          </li>

          <li>
            <strong>Exp 3 — Agglomerative Clustering + Dendrogram:</strong>
            <p class="mt-1">
              To cross-check K-Means, I ran Agglomerative clustering with Ward linkage on the same 2D scaled features and plotted a dendrogram.
            </p>

            <figure class="mt-3">
              <img src="figs/mall_dendrogram.png" alt="Agglomerative clustering dendrogram" class="w-full rounded border" />
              <figcaption class="text-sm text-gray-600 mt-1">
                Dendrogram shows a few large merges before distance jumps, supporting 4–5 high-level clusters.
              </figcaption>
            </figure>

            <p class="mt-2">
              The tree structure also suggested roughly 4–5 meaningful groups before distances spike, aligning with the choice of k = 5.
              Comparing K-Means labels to Agglomerative labels showed similar groupings with minor boundary changes.
            </p>
          </li>
        </ul>
      </section>

      <!-- Impact -->
      <section id="impact" class="mt-6">
        <h3 class="text-xl font-semibold">Impact & Limitations</h3>
        <p class="mt-2">
          Clustering here is basic but practical: it tells the mall who is loyal, who has money but isn’t spending, and who is
          mostly occasional traffic. That helps allocate marketing budget and design targeted campaigns.
        </p>
        <p class="mt-2">
          The limitations are clear:
        </p>
        <ul class="list-disc pl-6 mt-2 space-y-1">
          <li>No real purchase history (only an abstract “spending score”).</li>
          <li>No information on visit frequency, channel, or categories purchased.</li>
          <li>Risk of treating some groups as “less important” just because they don’t spend as much.</li>
        </ul>
        <p class="mt-2">
          In a real deployment, this kind of segmentation should be monitored so it doesn’t quietly justify ignoring low-income
          customers or pushing aggressive upselling only to high-income groups.
        </p>
      </section>

      <!-- Code -->
      <section id="code" class="mt-6">
        <h3 class="text-xl font-semibold">Code & Notebook</h3>
        <div class="space-y-2 mt-2">
          <p>
            <a class="underline text-blue-600" href="notebooks/MallCustomer_Clustering.ipynb" download>
              Download Notebook
            </a>
          </p>
          <div class="space-x-3 mt-2">
            <a class="inline-block px-3 py-2 rounded bg-black text-white"
               href="https://colab.research.google.com/github/Calvinzheng123/Calvinzheng123.github.io/blob/main/notebooks/MallCustomer_Clustering.ipynb"
               target="_blank" rel="noopener">
              Open in Colab
            </a>
            <a class="inline-block px-3 py-2 rounded bg-gray-200"
               href="https://nbviewer.org/github/Calvinzheng123/Calvinzheng123.github.io/blob/main/notebooks/MallCustomer_Clustering.ipynb"
               target="_blank" rel="noopener">
              View on nbviewer
            </a>
          </div>
        </div>
      </section>

      <!-- References -->
      <section class="mt-8">
        <h3 class="text-xl font-semibold">References</h3>
        <ul class="list-disc pl-6 mt-2">
          <li>
            Dataset:
            <a class="underline text-blue-600"
               href="https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python"
               target="_blank" rel="noopener">
              Mall Customer Segmentation Data (Kaggle)
            </a>
          </li>
          <li>Libraries: pandas, scikit-learn, matplotlib, seaborn, SciPy.</li>
          <li>Transparency: ChatGPT assisted with structuring text and HTML formatting for clarity.</li>
        </ul>
      </section>
    </section>
  </main>

  <footer class="max-w-3xl mx-auto p-6 text-sm text-gray-500">
    © <span id="y"></span> Calvin Zheng
  </footer>
  <script>document.getElementById('y').textContent = new Date().getFullYear();</script>
</body>
</html>
